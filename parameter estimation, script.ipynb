{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, morphology, color, util, filters, draw\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import sknw\n",
    "import argparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Processes a set of fluorescent or segmented images of mycelia and extracts relevant features.')\n",
    "\n",
    "parser.add_argument('--img_folder', dest=\"img_folder\", type=str, required=True,\n",
    "                    help='destination folder containing the image data set')\n",
    "parser.add_argument('--overview_file', dest=\"overview_file\", type=str, required=True,\n",
    "                    help='csv file in img_folder containing image details. see github repo for an example.')\n",
    "\n",
    "\n",
    "parser.add_argument('--fluorescence_dim', dest=\"fluorescence_dim\", type=int, required=True,\n",
    "                    help='colour channel to look for mycelium in (R=0, G=1, B=2).')\n",
    "parser.add_argument('--hours', dest=\"n_hours\", type=float, required=True,\n",
    "                    help='number of hours the mycelia have been growing. Use to scale e.g. branch frequency.')\n",
    "\n",
    "parser.add_argument('--hyphal_element_length', dest=\"hyphal_element_length_pixels\", type=int, default=50,\n",
    "                    help='estimated number of pixels per hyphal element. used for scaling parameters for generative mycelium model.')\n",
    "parser.add_argument('--small_object_limit', dest=\"small_object_limit\", type=int, required=False, default=10000,\n",
    "                    help='minimum size of connected binary pixels to keep when preprocessing binary image. larger values remove more noise')\n",
    "parser.add_argument('--small_object_limit_skeleton', dest=\"small_object_limit_skeleton\", type=int, required=False, default=1000,\n",
    "                    help='minimum size of connected binary pixels to keep when preprocessing binary, skeletonized image. larger values remove more noise')\n",
    "parser.add_argument('--median_filter_kernel', dest=\"median_filter_kernel\", type=int, required=False, default=5,\n",
    "                    help='size of median filter kernel used in smoothing edges of mycelia during preprocessing.')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "#args = parser.parse_args([\"--img_folder\", \"data/\", \"--overview_file\", \"image_overview.csv\", \"--fluorescence_dim\", \"2\", \"--hours\", \"24\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = args.img_folder\n",
    "overview_file = args.overview_file\n",
    "pixels_per_hyphal_element = args.hyphal_element_length_pixels\n",
    "n_hours = args.n_hours\n",
    "small_object_limit = args.small_object_limit\n",
    "small_object_limit_skeleton = args.small_object_limit_skeleton\n",
    "median_filter_kernel = args.median_filter_kernel\n",
    "fluorescence_dim = args.fluorescence_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_fluorescent_img(fname, fluorescence_dim):\n",
    "    \n",
    "    fl_img  = io.imread(fname)\n",
    "    fl_img = fl_img[:,:,fluorescence_dim]\n",
    "    fl_img = util.img_as_ubyte(fl_img)\n",
    "    \n",
    "    return fl_img\n",
    "\n",
    "def preprocess_image(fluorescent_img, threshold, small_object_limit, small_object_limit_skeleton, median_filter_kernel):\n",
    "\n",
    "    bin_img = fluorescent_img.copy()\n",
    "    bin_img[bin_img >= threshold] = 255\n",
    "    bin_img[bin_img < threshold] = 0\n",
    "\n",
    "    bin_img = bin_img.astype(np.bool)\n",
    "\n",
    "    bin_img = morphology.remove_small_objects(bin_img, min_size=small_object_limit, connectivity=2)\n",
    "\n",
    "    bin_img = filters.median(bin_img, selem=morphology.square(median_filter_kernel))\n",
    "\n",
    "    ske_img = morphology.skeletonize(bin_img)\n",
    "    ske_img = morphology.remove_small_objects(ske_img, min_size=small_object_limit_skeleton, connectivity=2)\n",
    "    \n",
    "    return ske_img\n",
    "    \n",
    "    \n",
    "\n",
    "def calculate_radius(p1, p2, p3):\n",
    "    # from https://stackoverflow.com/questions/28910718/give-3-points-and-a-plot-circle/50974391#50974391\n",
    "    temp = p2[0] * p2[0] + p2[1] * p2[1]\n",
    "    bc = (p1[0] * p1[0] + p1[1] * p1[1] - temp) / 2\n",
    "    cd = (temp - p3[0] * p3[0] - p3[1] * p3[1]) / 2\n",
    "    det = (p1[0] - p2[0]) * (p2[1] - p3[1]) - (p2[0] - p3[0]) * (p1[1] - p2[1])\n",
    "\n",
    "    if abs(det) < 1.0e-6:\n",
    "        return None\n",
    "\n",
    "    # Center of circle\n",
    "    cx = (bc*(p2[1] - p3[1]) - cd*(p1[1] - p2[1])) / det\n",
    "    cy = ((p1[0] - p2[0]) * cd - (p2[0] - p3[0]) * bc) / det\n",
    "\n",
    "    radius = np.sqrt((cx - p1[0])**2 + (cy - p1[1])**2)\n",
    "    return radius\n",
    "\n",
    "def calculate_curvatures(points, dist=30):\n",
    "    \n",
    "    curvatures_all = list()\n",
    "    \n",
    "    for i in range(len(ps)):\n",
    "\n",
    "        cur_curvatures = list()\n",
    "        cur_line = ps[i]\n",
    "\n",
    "        for i in range(dist, len(cur_line[:,0])-dist):\n",
    "\n",
    "            xm1, x, xp1 = cur_line[i-dist,0], cur_line[i,0], cur_line[i+dist,0]\n",
    "            ym1, y, yp1 = cur_line[i-dist,1], cur_line[i,1], cur_line[i+dist,1]\n",
    "\n",
    "            r = calculate_radius((xm1, ym1), (x,y), (xp1, yp1))\n",
    "            if r is not None:\n",
    "                cur_curvatures.append(1/r)\n",
    "                \n",
    "        curvatures_all.extend(cur_curvatures)\n",
    "    \n",
    "    if len(curvatures_all) != 0:\n",
    "        return curvatures_all\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def calculate_angles(graph, n_points = 10, n_min = 10):\n",
    "\n",
    "    nodes = graph.nodes()\n",
    "    angles = list()\n",
    "\n",
    "    for i in nodes:\n",
    "\n",
    "        if len(graph.edges(i)) != 3:\n",
    "            continue\n",
    "\n",
    "        neighbors_idx = [j for j in graph.neighbors(i)]\n",
    "        neighbors_pts = np.array([graph[i][j]['pts'] for j in neighbors_idx])\n",
    "        neighbors_len = [len(j) for j in neighbors_pts]\n",
    "\n",
    "        if sum(np.array(neighbors_len) > n_min) != 3:\n",
    "            continue\n",
    "\n",
    "        c = graph.nodes(data=True)[i][\"o\"]\n",
    "\n",
    "        # find closest n points\n",
    "        p = [0, 0, 0]\n",
    "        for i in range(3):\n",
    "            p[i] = neighbors_pts[i][np.argsort(np.sum((neighbors_pts[i] - c)**2, axis=1))[:n_points],:]\n",
    "\n",
    "        # linear regression through all sets\n",
    "        sets = [[0,1], [1,2], [0,2]]\n",
    "        r_vals = list()\n",
    "        for i in range(3):\n",
    "            a, b = sets[i][0], sets[i][1]\n",
    "            temp_data = np.concatenate((p[a], p[b]), axis=0)\n",
    "\n",
    "            _, _, r_value, _, _ = stats.linregress(temp_data)\n",
    "            r_squared = r_value**2\n",
    "\n",
    "            r_vals.append(r_squared)\n",
    "\n",
    "        best_idx = sets[np.argmax(r_vals)]\n",
    "        last_idx = list(set([0,1,2]).difference(set(best_idx)))[0]\n",
    "\n",
    "        # create two lines, one through two best sets and one through last set. \n",
    "        temp_data = np.concatenate((p[best_idx[0]], p[best_idx[1]]), axis=0)\n",
    "        slope1, _, _, _, _ = stats.linregress(temp_data)\n",
    "        slope2, _, _, _, _ = stats.linregress(p[last_idx][:,0], p[last_idx][:,1])\n",
    "        \n",
    "        if np.isnan(slope1): slope1=1000\n",
    "        if np.isnan(slope2): slope2=1000\n",
    "\n",
    "        alpha, beta = np.arctan(slope1)*180/3.14, np.arctan(slope2)*180/3.14\n",
    "        angle = alpha - beta\n",
    "        #angle = (m1 - m2)*180/3.14\n",
    "        if angle < 0:\n",
    "            angle = -angle\n",
    "        if angle > 90:\n",
    "            angle = 180 - angle\n",
    "\n",
    "        angles.append(angle)\n",
    "        \n",
    "    return angles\n",
    "\n",
    "def box_fractal_dim(Z, threshold=0.9):\n",
    "    # From https://github.com/rougier/numpy-100 (#87)\n",
    "    # Only for 2d image\n",
    "    assert(len(Z.shape) == 2)\n",
    "    \n",
    "    def boxcount(Z, k):\n",
    "        S = np.add.reduceat(\n",
    "            np.add.reduceat(Z, np.arange(0, Z.shape[0], k), axis=0),\n",
    "                               np.arange(0, Z.shape[1], k), axis=1)\n",
    "\n",
    "        # We count non-empty (0) and non-full boxes (k*k)\n",
    "        return len(np.where((S > 0) & (S < k*k))[0])\n",
    "\n",
    "    # Transform Z into a binary array\n",
    "    Z = (Z < threshold)\n",
    "\n",
    "    # Minimal dimension of image\n",
    "    p = min(Z.shape)\n",
    "\n",
    "    # Greatest power of 2 less than or equal to p\n",
    "    n = 2**np.floor(np.log(p)/np.log(2))\n",
    "\n",
    "    # Extract the exponent\n",
    "    n = int(np.log(n)/np.log(2))\n",
    "\n",
    "    # Build successive box sizes (from 2**n down to 2**1)\n",
    "    sizes = 2**np.arange(n, 1, -1)\n",
    "\n",
    "    # Actual box counting with decreasing size\n",
    "    counts = []\n",
    "    for size in sizes:\n",
    "        counts.append(boxcount(Z, size))\n",
    "\n",
    "    # Fit the successive log(sizes) with log (counts)\n",
    "    coeffs = np.polyfit(np.log(sizes), np.log(counts), 1)\n",
    "    return -coeffs[0]\n",
    "\n",
    "def get_dist_params(measure, data):\n",
    "    if measure == \"curvature\":\n",
    "        dist_name = \"gamma\"\n",
    "        dist = getattr(stats, dist_name)\n",
    "        p = dist.fit(data)[0:2] #a, scale in scipy\n",
    "    elif measure == \"branching\":\n",
    "        dist_name = \"beta\"\n",
    "        data = [i/max(data) for i in data]\n",
    "        dist = getattr(stats, dist_name)\n",
    "        p = dist.fit(data)[0:2] #a, b in scipy\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_overview = pd.read_csv(img_folder+overview_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "branching_freqs = list()\n",
    "curvatures_all = list()\n",
    "angles_all = list()\n",
    "internodal_all = list()\n",
    "box_counting_dims_all = list()\n",
    "\n",
    "for idx in range(len(img_overview)):\n",
    "\n",
    "\n",
    "    fluorescent_img = import_fluorescent_img(img_folder + img_overview.at[idx,\"target_img_fname\"], fluorescence_dim=fluorescence_dim)\n",
    "    \n",
    "    skeleton = preprocess_image(fluorescent_img, img_overview.at[idx,\"binary_threshold\"],\n",
    "                                small_object_limit, small_object_limit_skeleton, median_filter_kernel)\n",
    "    \n",
    "    # build graph from skeleton\n",
    "    graph = sknw.build_sknw(skeleton)\n",
    "\n",
    "    # draw node by o\n",
    "    nodes = graph.nodes()\n",
    "    bs = np.array([nodes[i]['o'] for i in nodes if len(graph.edges(i))>=3])\n",
    "    ts = np.array([nodes[i]['o'] for i in nodes if len(graph.edges(i))<=2])\n",
    "    \n",
    "    ps = list()\n",
    "    internodal_lengths = list()\n",
    "\n",
    "    for (s,e) in graph.edges():\n",
    "        ps.append(graph[s][e]['pts'].astype(np.int32))\n",
    "        \n",
    "        if len([j for j in graph.neighbors(s)]) == 3 and len([j for j in graph.neighbors(s)]) == 3:\n",
    "            internodal_lengths.append(len(graph[s][e]['pts'].astype(np.int32)))\n",
    "        \n",
    "    curvatures = calculate_curvatures(ps)\n",
    "        \n",
    "    branch_occurence = (len(bs))/graph.size(weight=\"weight\")    \n",
    "    n_hyphal_elements = (graph.size(weight=\"weight\"))/pixels_per_hyphal_element\n",
    "    \n",
    "    curvatures_all.append(curvatures)\n",
    "    branching_freqs.append(branch_occurence*pixels_per_hyphal_element/n_hours)\n",
    "    \n",
    "    angles = calculate_angles(graph)\n",
    "    angles_all.append(angles)\n",
    "    \n",
    "    internodal_all.append(internodal_lengths)\n",
    "    \n",
    "    box_counting_dims_all.append(box_fractal_dim(skeleton))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "branching_freq_avg = np.mean(branching_freqs)\n",
    "curvature_params = get_dist_params(\"curvature\", [item for sublist in curvatures_all for item in sublist]) #gamma dist, params scale\n",
    "angle_params = get_dist_params(\"branching\", [item for sublist in angles_all for item in sublist]) #beta dist, params a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = pd.DataFrame([[\"branching_frequency\", \"curvature_gamma_a\", \"curvature_gamma_scale\", \"angle_beta_a\", \"angle_beta_b\"], \n",
    "                          [branching_freq_avg] + list(curvature_params) + list(angle_params)])\n",
    "\n",
    "export_df = export_df.rename(columns=export_df.iloc[0]).drop(export_df.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df.to_csv(\"graph_parameters.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
